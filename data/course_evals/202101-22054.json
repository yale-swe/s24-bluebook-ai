{
    "crn_code": "22054",
    "season": "202101",
    "enrollment": {
        "enrolled": 98,
        "responses": 54,
        "declined": 6,
        "no response": 33
    },
    "ratings": [
        {
            "question_id": "YC402",
            "question_text": "Your level of engagement with the course was:",
            "options": [
                "very low",
                "low",
                "medium",
                "high",
                "very high"
            ],
            "data": [
                0,
                4,
                10,
                10,
                2
            ]
        },
        {
            "question_id": "YC404",
            "question_text": "What is your overall assessment of this course?",
            "options": [
                "poor",
                "fair",
                "good",
                "very good",
                "excellent"
            ],
            "data": [
                4,
                3,
                9,
                7,
                3
            ]
        },
        {
            "question_id": "YC405",
            "question_text": "The course was well organized to facilitate student learning.",
            "options": [
                "strongly disagree",
                "disagree",
                "neutral",
                "agree",
                "strongly agree"
            ],
            "data": [
                4,
                2,
                11,
                7,
                2
            ]
        },
        {
            "question_id": "YC406",
            "question_text": "I received clear feedback that improved my learning.",
            "options": [
                "strongly disagree",
                "disagree",
                "neutral",
                "agree",
                "strongly agree"
            ],
            "data": [
                4,
                1,
                7,
                10,
                4
            ]
        },
        {
            "question_id": "YC407",
            "question_text": "Relative to other courses you have taken at Yale, the level of <u>intellectual challenge<\/u> of this course was:",
            "options": [
                "much less",
                "less",
                "same",
                "greater",
                "much greater"
            ],
            "data": [
                0,
                1,
                5,
                16,
                4
            ]
        },
        {
            "question_id": "YC408",
            "question_text": "Relative to other courses you have taken at Yale, the <u>workload<\/u> of this course was:",
            "options": [
                "much less",
                "less",
                "same",
                "greater",
                "much greater"
            ],
            "data": [
                0,
                1,
                8,
                13,
                4
            ]
        },
        {
            "question_id": "YC601",
            "question_text": "Which of the following best describes your mode of learning in this course?",
            "options": [
                "recorded lecture",
                "live virtual lecture",
                "in-person lecture",
                "virtual seminar or other discussion format",
                "in-person seminar or other discussion format",
                "virtual lab",
                "in-person lab",
                "other or multiple (please describe below)"
            ],
            "data": [
                11,
                16,
                0,
                0,
                0,
                0,
                0,
                2
            ]
        }
    ],
    "narratives": [
        {
            "question_id": "YC401",
            "question_text": "What knowledge, skills, and insights did you develop by taking this course?\n(Your anonymous response to this question may be viewed by Yale College students, faculty, and advisers to aid in course selection and evaluating teaching.)",
            "comments": [
                "Different structures of deep learning networks such as convolutional neural networks, graph neural networks, and also theory about generalizability of deep neural networks",
                "Good insights into practical deep learning.  While I already knew a decent amount of the conceptual basis of ML, this class really taught me the nitty gritty details.  I feel like I could really go out and use these skills in the real world now.",
                "I learned about current deep learning techniques and architectures (AEs, GANs, CNNs, RNNs, ODEs, etc). There is also a bit of theory covered in the class. However, I would say most of the information is extremely high-level, which is to be expected given the breadth of this course.",
                "I learned about some of the math that goes into deep learning models. I also learned about some new deep learning models that are being used in research.",
                "Very cool experience learning about the predictive & modeling capabilities of computers",
                "I learned a lot about the theory behind and practical use of neural networks.",
                "Familiarity, basic fluency, basic theoretical understanding, and basic implementation skills with neural networks. A sense of deep learning as an active area of research",
                "A great number of deep learning topics were covered - gradient descent, backprop, loss and activation functions, regularization, auto encoders, GANs, CNNs, RNN\/LSTM\/Transformers, graph neural networks, and neural tangent kernels are some examples.",
                "I learned the fundamental aspects of deep learning. The first half of the course was great. The second half of the class seemed forced and we didnt go into depth about anything (neural ODE, GNN, etc.) . Honestly you could learn most of the material by just reading the two textbooks and will probably need to do that anyway if you do take the class.",
                "I don't know - everything I was supposed to learn from Smita about deep learning architectures and applications I learned through GitHub, Medium articles, and the TA Kincaid.",
                "Deep Learning concepts (backpropagation, gradient descent, regularization, etc), deep learning models (NN, CNN, GNN, GAN, RNN, Transformer, Autoencoders, Neural ODEs, etc), deep learning research and concepts (universality, loss landscape, etc). Gained a familiarity with PyTorch, Jupyter Notebook.",
                "Developed understanding of deep neual networks, practiced their implementation, and worked on a project related to deep learning",
                "I gained a high-level understanding of some state-of-the-art deep learning practices. I understand why certain architectures, like convolutional networks, may work better in some settings as opposed to recurrent networks. I think this class helped me gain a lot of intuition and practice with working with different types of models, and definitely helped me do a better job of picking architectures moving forward. It also exposed us to a lot of recent research in the field, which I thought was very engaging.",
                "I learned about Depp learning architectures, activation functions, techniques, and the theory behind them.",
                "Learned about various kinds of neural networks",
                "Pytorch, various types of neural networks, heuristics to boost learning and debugging."
            ]
        },
        {
            "question_id": "YC403",
            "question_text": "What are the strengths and weaknesses of this course and how could it be improved?\n(Your anonymous response to this question may be viewed by Yale College students, faculty, and advisers to aid in course selection and evaluating teaching.)",
            "comments": [
                "strengths; The material is fascinating, and the Professor is great\r\nweaknesses: it consumes a LOT of time to do the homework. Make sure you are not taking a very heavy course load.",
                "This first pset was an absolute mess.  Stupidly difficult and almost no instruction was provided.  After that they got way better.  Lecture was hard to understand at points but watching them back after the fact often cleared things up.",
                "I think the strengths of this course lie in the lecture slides (sometimes) and the extra materials such as research papers that Smita provides at the end of each lecture. Smita knows a lot about the field, and that results in some interesting ideas being discussed. That being said, there are definitely more glaring weakness in this course than strengths. Problem sets were often graded extremely late, and the material they covered was arguably not in the lectures. I think there is a disconnect in this class between Smita's lectures being more theory and not reliant on actual code and the problem sets being mainly programming. Online tutorials, not lectures or office hours, become your best friend to learn how to do the problems on the homework. Furthermore, despite the content being interesting in a vacuum, lectures are extremely dry and difficult to follow under Smita. There is a heavy assumption of prior knowledge of deep learning in many lectures that was simply not mentioned in the prerequisites for this class. Sometimes, I would find myself understanding the first half of the lecture only for the second half to be completely incomprehensible when the focus shifted to specific research that required knowledge that the first half did not provide.",
                "The course covers a lot of interesting material, but I felt like it was rather unsatisfying. \r\n\r\nThe prereqs feel like a lie. I think some knowledge of machine learning\/deep learning should be a prerequisite because Professor Krishnaswamy assumes this knowledge and does not review any of it. \r\n\r\nAlso beware: not a single line of code is shown in class. Nor are details of implementation touched upon. Hearing this you might think: \"ok great i'll understand the theory and math behind deep learning better then\", but we go through the math at too high of a level\/speed to get a solid grip on it. I feel like this class could be divided into two semesters so it was appropriately taught.",
                "Solid class. Really cool how it applies to so much stuff. Homeworks were hard and it was tough being so independent with some of the really technical stuff, but a lot of this was due to COVID",
                "I thought it was good but lectures could've been improved with more practical examples.",
                "For me a strength of this course was the balance of survey material and opportunities for focused exploration such as through the final project. I thought that the readings were really interesting and provided cool opportunities to learn about this area of research as an active area of study. The final project was also a really cool way to apply what we'd been learning throughout the semester, and I thought the proposal and progress report were helpful for staying on track. The lectures were also good, although sometimes I felt like there was a lot covered in them and it didn't quite flow like a normal math or cs class, but that's partly due to the nature of the subject and how much new work is already seminal. One weakness though was that there were some bugs in the source code we were given for the psets, so more time than I would have liked was spent debugging the given code--I hope this can be fixed for future classes",
                "The strength of the course was the thorough descriptions and papers presented on each topic.  Personally, I feel that the breadth of information covered was a bit too much.  I would have preferred a class that focused in depth on fewer topics.",
                "Strength: very little; Kincaid (Ula); relatively easy assignments.  Weakness: very broad lectures, cover too much instead of depth; poorly organized exams\/assignments and lots of mistakes in them until the last day; unresponsive professor for weeks at a time.\r\n\r\nClass could be improved by more engagement by the professor",
                "Strengths: interesting material, freedom in final project\r\nWeaknesses: Don't even get me started. All weaknesses stem from Smita. From obtuse, code-less(!?) lectures on deep learning theory, to consistent rudeness to students and even guest speakers, to making the ULAs *write* the assignments, to making the final exam and final project collectively worth 2\/3 of the overall grade, to never responding to emails, to...yeah it was just bad.\r\n\r\nThe largest improvement could be made by replacing the professor with someone passionate about educating students about the exciting and budding field of deep learning, who can showcase not only the theory but also the code behind some of the greatest endeavors in machine learning\/artificial intelligence.",
                "Very interesting concepts, and highly cutting edge material included. Felt like I was gaining skills directly applicable to research. Lectures were quite dry, problem sets could be quite long (although extensions provided)",
                "Course did a good job of covering the various new developments in deep learning, but it could have gone in deppth to some of the new developments in deep learning rather than spending so much time on the mathematics, which",
                "I think the class lectures are difficult to learn a lot from at times because most of the material can be properly learned through the supplemental readings in more detail. Furthermore, the pace of the class when covering unintuitive concepts made it difficult to follow. I do not think this is a weakness, however, because I still found the material accessible enough to people like me without machine learning experience that I was able to learn a great deal without any prior knowledge. In the future, I think the course could be improved with more examples in class that could maybe bring the lecture from a high-level abstract overview to a more grounded and relatable concept. I found myself learning most after class, as is natural with most CS classes, but in this one in particular, since one of the homework assignments even asked us to read a tutorial on Pytorch prior to starting.",
                "The course paints broad strokes across the entire deep learning landscape, which can make the material seem overwhelming. I think focusing on more specific fundamental deep learning techniques, such as CNNs and RNNs, may make the course more digestible.",
                "The TAs were really engaged and found creative ways to assess our understanding of lectures. However, lectures were often far removed from what was needed for psets and a lot of knowledge was assumed. More background on the more mathematical or conceptual parts of the course would be useful."
            ]
        },
        {
            "question_id": "YC602",
            "question_text": "Among the practices in this course geared toward learning during the COVID-19 pandemic, which succeeded and which could be improved? Please comment on course practices that allowed for virtual engagement. (Your anonymous response to this question may be viewed by Yale College students, faculty, and advisers to aid in course selection and evaluating teaching.)",
            "comments": [
                "Smita and the ULAs were generally receptive to granting extensions on assignments. In particular, I found Kincaid to be extremely helpful as a ULA, and he hosted several Discord sessions (also added more office hours consistently) where students were allowed to ask last-minute questions for problem sets.",
                "Recorded lectures are nice. I appreciate that she brought in some guest lecturers.",
                "I thought recorded lectures were very helpful. The flexible office hours were nice, and liked being able to sign up for ULA office hours. I really, really appreciated some of the flexibility in deadlines, as some of the psets took longer than expected",
                "The transition of the courses to the virtual format was fine and did not greatly impact my learning.",
                "The Zoom lectures simply failed because the professor made them non-educational and often rescheduled them in favor of attending her research meetings.",
                "Virtual problem sets and classes worked fine, as did the take home final. Upload of class recordings often took quite a while",
                "I thought the class did very well to adapt, with very frequent office hours, opportunities to ask questions, and plenty of supplemental material.",
                "More office hours.",
                "Recorded lectures are helpful",
                "Office hours on discord might have been slightly confusing since a lot of the threads get mixed up. Piazza was a great resource however. Recorded lectures were really useful."
            ]
        },
        {
            "question_id": "YC409",
            "question_text": "Would you recommend this course to another student? Please explain.\n(Your anonymous response to this question may be viewed by Yale College students, faculty, and advisers to aid in course selection and evaluating teaching.)",
            "comments": [
                "Yes, you learn a lot of valuable material. Just be very aware that the course load is heavy and keeping up does require a lot of work, especially when the material gets hard towards the end.",
                "Would recommend.",
                "I would probably recommend this course to another students.  It was definitely challenging but I enjoyed it.  The psets felt very trial-by-fire, but I definitely learned quite a bit from them.",
                "No. I would absolutely not recommend this course for any undergraduates without any significant prior experiences with deep learning techniques and architectures. It seems as if only the graduate students with research experience under their belt were much more engaged in the class and able to participate in lectures. While I did leave with some understanding and knowledge of the course material I didn't have before, I really can't say it was worth the effort. The material was often high enough level that it could easily be found online in blogs or other resources. However, the biggest issue I have with this course is the prerequisites only being \"basic prior knowledge in linear algebra and probability\", which I found to be completely untrue throughout the course. If this prerequisite was updated to be more accurate, I would not have as many complaints with this course assuming knowledge of particular architectures during the lecture. It is also definitely worth noting that while Smita is an incredibly intelligent and gifted researcher, I don't believe she conveys her knowledge effectively at all in her lectures. Sometimes, it really felt like Smita wanted to be at lecture even less than the students, and this resulted in lectures being very boring despite what the content might suggest.",
                "Probably not unless you already have some experienced with deep learning. Professor Krishnaswamy is a fantastic researcher, but I don't think she prioritizes teaching as much. You would probably be better off learning this stuff off of articles online. This felt like a bit of a survey course at times, and there just wasn't enough time spent explaining things to get a solid understanding of the material.",
                "Yes if you think ML and DL are cool",
                "I think it was good, but be prepared to learn some programming on your own if you don't have a ton of experience with pytorch.",
                "I would only recommend this course to students who have truly completed the prerequisites and who are very interested in this subject. I.e. I would only take after linear algebra, multivariable calculus, probability theory, and experience with python programming. You might be able to do the class without one or more of these, but I don't think you would get as much out of it. This background is super important for machine learning and deep learning, and I think studnets would be better off in the long run focusing on foundations if they don't have a prereq. But I think if you have the prereqs then it can be a good course. Start the psets early though, partly because they weren't always worded clearly and sometimes had bugs, so this took time to figure out sometimes. But it is an exciting subject and a cool way to learn it if it's a good fit for you!",
                "I would recommend this to anyone interested in deep learning and has time for a work-intensive class.",
                "Definitely would not recommend with Prof Krishnaswamy. She seems like an amazing research prof but also seems that she could hardly care about our class. She would sometimes go weeks without looking at Piazza and answering questions. She was super disorgnanized and a lot of the things that she wrote had mistakes in them or werent clear (like the exam). She was a solid lecturer but not great. Also, its a bit crazy that a ULA (whos amazing) is writing all of the psets.",
                "NO!!! Take any other class - you can learn all of this much better through numerous free online resources, including Andrew Ng's Stanford lectures, Nielson's textbook, Github repositories, Medium articles, etc. Please do yourself a favor and don't waste your time with this one. You will suffer through horrible teaching, no guidance on the final project, and almost no helpful guidance from ULAs who didn't write the assignments. Kincaid was the only reason anyone ever completed the assignments since he wrote them; kudos to him for helping us.",
                "Great if you are interested in ML research or careers, good overview of many types of neural networks. The course itself isn't run that well and the final project can be a drain so plan accordingly",
                "Yes, if you are interested in getting a good survey of deep learning techniques and implement some of them yourself. Don't go in expecting to have a great mathematical or theoretical understanding of the techniques used",
                "I would if you have the time and interest to commit to this topic. This class would be frustrating for anybody not interested in it, and the organizational flow can make it difficult to fully engage with it. However, if you have the time, then it is fully possible to learn a lot from the long but engaging problem sets, and the many interesting concepts mentioned in lecture. For anybody with an interest in deep learning at a high level, this class was a lot of fun and I particularly enjoyed applying it in a end-of-term project.",
                "Yes, if you want to get into deep learning this is a great course to do so.",
                "Yes, if you are interested in machine learning and neural networks",
                "I would if the student wants a broad introduction to multiple architectures and a crash course in Pytorch and Deep Learning debugging. Conceptually, my understanding remained stuck to higher level insights."
            ]
        },
        {
            "question_id": "YC601N",
            "question_text": "Please list any other mode(s) of learning, including any combination or variation of the above options.",
            "comments": [
                "I went to live virtual lectures in the beginning, then I shifted to recorded lectures for the remainder of the semester.",
                "I would watch recorded lectures when lecture times were moved.",
                "We had mostly live virtual lectures, with the occasional recorded lecture when the professor was busy during class time.",
                "Mostly live virtual lecture, but also through office hours. And of course through assignments: psets, final project, final exam, readings",
                "None",
                "There was a mode of learning in this class?",
                "I attended live virtual lectures, but mainly relied on recorded lectures, lecture notes, supplemental readings, and office hours with Kincaid.",
                "Also recorded",
                "Recorded lecture."
            ]
        }
    ],
    "extras": {
        "title": " CPSC 552 01\/CB&B 663 01\/AMTH 552 01\/CPSC 452 01\n        Deep Learning\/DeepLearningTheoryApplications "
    }
}