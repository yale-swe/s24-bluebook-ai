{
    "crn_code": "12840",
    "season": "202203",
    "enrollment": {
        "enrolled": 50,
        "responses": 19,
        "declined": null,
        "no response": null
    },
    "ratings": [
        {
            "question_id": "YC402",
            "question_text": "Your level of engagement with the course was:",
            "options": [
                "very low",
                "low",
                "medium",
                "high",
                "very high"
            ],
            "data": [
                0,
                4,
                6,
                4,
                1
            ]
        },
        {
            "question_id": "YC404",
            "question_text": "What is your overall assessment of this course?",
            "options": [
                "poor",
                "fair",
                "good",
                "very good",
                "excellent"
            ],
            "data": [
                0,
                3,
                8,
                3,
                2
            ]
        },
        {
            "question_id": "YC405",
            "question_text": "The course was well organized to facilitate student learning.",
            "options": [
                "strongly disagree",
                "disagree",
                "neutral",
                "agree",
                "strongly agree"
            ],
            "data": [
                1,
                4,
                6,
                4,
                0
            ]
        },
        {
            "question_id": "YC406",
            "question_text": "I received clear feedback that improved my learning.",
            "options": [
                "strongly disagree",
                "disagree",
                "neutral",
                "agree",
                "strongly agree"
            ],
            "data": [
                0,
                2,
                7,
                5,
                0
            ]
        },
        {
            "question_id": "YC407",
            "question_text": "Relative to other courses you have taken at Yale, the level of intellectual challenge of this course was:",
            "options": [
                "much less",
                "less",
                "same",
                "greater",
                "much greater"
            ],
            "data": [
                0,
                4,
                3,
                7,
                1
            ]
        },
        {
            "question_id": "YC408",
            "question_text": "Relative to other courses you have taken at Yale, the workload of this course was:",
            "options": [
                "much less",
                "less",
                "same",
                "greater",
                "much greater"
            ],
            "data": [
                1,
                4,
                6,
                4,
                0
            ]
        }
    ],
    "narratives": [
        {
            "question_id": "YC401",
            "question_text": "What knowledge, skills, and insights did you develop by taking this course?",
            "comments": [
                "Some interesting ideas about how to probe the underlying geometric or topological structure of data. A lot of the work was on manifold learning and data visualization. We were presented with quite a bit of rather specific research.",
                "Manifold learning, geometry and machine learning. Many hot and interesting topics that offer new perspectives on data dimensionality reduction.",
                "A bunch of things, but we mainly focused on learning on graphs from a toplogical / geometric viewpoint. Some neural network stuff. Sort of a grab bag of pure results motivating applications",
                "Data usually lies near a lower-dimensional manifold in high-dimensional (Euclidean) feature space. This allows for the traditional techniques of geometry and topology to be applied to studying and training neural networks that can do wonderful things: dimensionality reduction, variational autoencoding, etc.",
                "Lots of theoretical underpinnings and architectural skills for machine learning.",
                "It's hard to pinpoint the exact skills we learned - a lot of the stuff we learned was a lot of the research done by the professors and related fields/methods, which I guess can generally be summarized by stuff like (1) dimensionality reduction methods, (2) theoretical basis for dimension reduction (i.e., manifolds, diffusion, curvature), (3) neural networks and embeddings, (4) topological data analysis. I think what was neat is that all these were presented as methods used in current research, but with the downside that it's really a wide/semi-random hodgepodge of everything the professors have and are doing, so it's hard to say that \"you will learn (specific skill x).\" \r\n\r\nOk, with that said, the problem sets taught me to (1) implement methods in dimension reduction (2) implement neural networks and (3) prove some theoretical results about the aforementioned (and a little more).",
                "Topological ideas behind ML and data visualization.",
                "Neural networks, the manifold hypothesis, basic topology",
                "I became a better coder and learned some of the basics of machine learning and various data analysis techniques.",
                "Learned about new research on manifolds potentially being a new mathematical base to interpret and predict high-dimensional data"
            ]
        },
        {
            "question_id": "YC403",
            "question_text": "What are the strengths and weaknesses of this course and how could it be improved?",
            "comments": [
                "I really enjoyed Ian and Smita's lectures. However, I felt lost during the guest lecturers and Jeff's lectures. I wish we had more lectures given by Ian and Smita throughout the semester. I also wish some machine learning experience and more coding background was stated as a prerequisite.",
                "I really enjoyed this class, the teachers gave us many concepts of manifold learning from a mathematical and applied perspective. I liked the teachers always invite different lecturers to discuss many new topics, which are very inspiring. I think the weaknesses is that the course covered too many topics but each one was only introductory and if there are more in-depth discussions, it will be better.",
                "The instruction was overall very good, but some things were glossed over maybe too quickly. I got the sense that some students were much better prepared than others.",
                "The course is invaluable for people interested in the research field! I was not  I was tangentially interested in the geometry and topology  which is why the PowerPoint lecture format sort of annoyed me, since many details were skipped. BUT: I think the idea of this was to give students a high-level overview, and if they are interested about a certain subject, that they do some googling, read the suggested papers, and figure some things out on their own (this is probably the CS mentality that I was not expecting from a math course, but it is very chill).",
                "Awesome course content. I think the presence of a central textbook or more detailed lecture notes would have been really helpful. Bringing together a bunch of sources with disparate, sometimes conflicting notational conventions was cumbersome and disorienting at times. I think as a result of the media they chose to teach (realtime chalkboard writing vs slides) Ian usually went at a pace that was easier to follow/take adequate notes, and Smita sometimes went a little too fast for me to keep up.",
                "Strengths: The professors are at the front of their field. Weaknesses: the professors are at the front of their field. It was very cool to be able to learn from the professors because they have a lot of direct knowledge and are currently doing the things they teach, and they brought in guest speakers on cutting edge research. But at times I found myself out of my depth, e.g. as a math major I wasn't already familiar with a lot of CS concepts that were glossed over (e.g. with machine learning). On the whole, I think it was possible for me to keep up nonetheless, just know that the prerequisites (currently: Math 302/equivalents + CS 112 I think) might not be 100% honest. (The prerequisites are honestly the specific topics the professors need, e.g. diffeqs or group theory or deep learning, depending on the context. If you haven't seen all of these before, you probably don't need to, just be warned that the profs may kinda pull these out of a bag as needed.) \r\n\r\nOn the whole though, I learned a lot through the course, and I think the professors did a decent job of introducing the material over time, or introducing just enough material as relevant without needing all the background. I think the problem sets were also generally helpful, though the CS questions took disproportionately more time than the math ones. (I also think some more pointers with the CS problems could have helped.) There was also one CS problem set that required us to install stuff with Pytorch and other python packages, which I managed to figure out, but which took a few hours of the time doing the problem set, and which I wish wasn't something they assumed we just had beforehand. But, to be fair, I guess this was a grad course cross listed in the CS department. In any case, I do think that the questions that asked us to implement things in CS were pretty long, but also they were cool and I learned from them. The math problems are also pretty doable and helped with the concepts. Overall the workload felt pretty fair, we only had 4 problem sets, so the work was really occasional, which wasn't too bad. (As I said though, the CS problem sets were a huge spike of work.) With that said we had a final project on top of a take home final, which was a bit brutal, though I guess it counterbalanced the fact that we didn't have any midterms.\r\n\r\nI think the lecture structures were also a double edged sword. Since they were ~2 hours consecutively on Fridays, the lectures allowed for, e.g., a math lecture on theory following a CS lecture on implementation, which helped smooth out wrinkles in understanding, but they were also very long. I also wish the CS lectures had maybe done more with showing implementation/examples, a lot of the content was theory heavy and hard to translate into implementation on the problem sets. I did appreciate the amount of materials the professors gave out though, e.g. notes and lecture slides.",
                "The lectures are fun but kinda unstructured.",
                "Every lecture was really interesting, and lectures by Ian and Smita were well-organized and built on each other and into the homeworks. I think the concept of the course was cool, but it ran into difficulties with students from math / CS backgrounds not being fully prepared for the other side of the class.",
                "Its a good subject matter that needs a courseits a good thing the class exists. But the syllabus felt a bit meandering at times.",
                "Strengths: Reasonable expectations, supportive ULAs\r\n\r\nWeaknesses: One of the psets didn't work on my computer (and some others'), guest lectures seemed more geared towards the professors doing the research than to us, grading was unnecessarily harsh"
            ]
        },
        {
            "question_id": "YC409",
            "question_text": "Would you recommend this course to another student? Please explain.",
            "comments": [
                "At the end of class, Smita mentioned how this course was not going to be offered again, and instead was going to be split into an advanced linear algebra course taught by Ian and some of the geometric elements would be incorporated into her unsupervised learning class. I think this is a good decision. I think both of those courses would be excellent.",
                "Sure.",
                "If you're genuinely interested in the material and want to beef up your applied math know-how, do it. Just make sure you can code in python, or are willing to learn.",
                "This course is easy. Maybe even a joke. But the real question is: are you a clown? On a more serious note, the course is based on teaching yourself, since the lectures suck if you are expecting to learn some stuff in a thoughtful, linear way. But, I kind of enjoy what this course can be: a time to explore and learn only the things you care about, and you can do as much googling and research as you want, but at the end of the day the grading was extremely lenient when I took it, so you dont have to learn anything you dont want to.",
                "Absolutely, if they had enough of a quantitative background. It was fascinating, and very useful for my future research interests. I was so excited to show up to each and every lecture.",
                "I think this is a cool class to take, though I think it's very specifically oriented towards students who really like BOTH math and CS. I signed up for the cool maths, and there was cool maths, it's just that I clocked out with respect to some of the CS components. To be fair, the CS is cool and implementing it felt really satisfying, but if you're a math major and aren't too big of a fan of CS, know that it is 1/2 a CS class. (Maybe more like 2/3. But alas.) And vice versa. Also know that the topics are very fresh and new research, which has the upside of being fresh and new and cool, but can have the downside of the course being more open ended and harder to give a direction to (since the topics ended up becoming presentations on people's research). So that's really up to your preference I think.",
                "Fun course for sure, but I don't feel like I learned that much. The math topics are all over the place, and the data science topics are not that closely related to the math anyway.",
                "Its in a weird spot. Who is this class for? People with ML experience will just learn some vector calc and TDA. People with no ML experience will probably feel a bit lost. I think the class needs to commit more to an audience.",
                "It's hard to say, especially because Ian and Smita said this course in this exact form won't be offered again. There's a lot of potential in what we did, but it was clear that the material needed a lot of fine-tuning. I got the sense over the course of the semester that this was really meant to be a graduate seminar where we all talked about the professors' new research together, heard from other professors/postdocs doing the same stuff elsewhere, and were (excessively harshly) graded on largely rubber-stamp homeworks. The psets themselves were not difficult at all, except when they accidentally made them hard (i.e. realized after the fact that the Colab notebooks didn't run correctly for everyone or that a problem unintentionally presupposed ridiculous background knowledge, or worse, was unsolved ._.). Sometimes Smita would write a problem Ian didn't know how to do, for example, or vice versa, showing that they were clearly still developing the course on the fly. The guest lectures also seemed more aimed at the professors/TAs in the room researching manifolds and machine learning than the students trying to get a grasp of it for the first time. (Ian and Smita often had more questions for the guest lecturers than all of the students.) This isn't a problem for future years as much as it's a reflection of our year really being guinea pigs for learning this stuff. I appreciate Ian and Smita being kind and supportive through the whole process - it's far from easy to run a new course like this, especially one intended to bring advanced math and CS students together who may not know much in the other field - but what survives of it as units here and there in future courses needs to either be more geared towards student learning or explicitly laid out as a common exploration where the expectation is something other than the stereotypical post-course understanding of the material."
            ]
        }
    ],
    "extras": {
        "title": "AMTH 322 01/CPSC 644 01/MATH 322 01/MATH 522 01 - Geometric & Topological in ML"
    },
    "sentiment_info": {
        "YC401": {
            "sentiment_labels": [
                "POSITIVE",
                "POSITIVE",
                "NEGATIVE",
                "POSITIVE",
                "POSITIVE",
                "POSITIVE",
                "POSITIVE",
                "POSITIVE",
                "POSITIVE",
                "POSITIVE"
            ],
            "sentiment_scores": [
                0.9978675842285156,
                0.9986590147018433,
                0.9454208016395569,
                0.9983987212181091,
                0.9983710646629333,
                0.9964829683303833,
                0.9973949193954468,
                0.9954994320869446,
                0.9986066222190857,
                0.9973477125167847
            ],
            "sentiment_counts": {
                "POSITIVE": 9,
                "NEGATIVE": 1
            },
            "sentiment_distribution": {
                "POSITIVE": 0.9,
                "NEGATIVE": 0.1
            },
            "sentiment_overall": [
                "POSITIVE",
                0.9
            ]
        },
        "YC403": {
            "sentiment_labels": [
                "POSITIVE",
                "POSITIVE",
                "POSITIVE",
                "POSITIVE",
                "POSITIVE",
                "POSITIVE",
                "NEGATIVE",
                "POSITIVE",
                "POSITIVE",
                "POSITIVE"
            ],
            "sentiment_scores": [
                0.9980729818344116,
                0.9988829493522644,
                0.9986145496368408,
                0.9988577365875244,
                0.9980560541152954,
                0.9988245368003845,
                0.9797022938728333,
                0.9988054037094116,
                0.9986479878425598,
                0.9973495006561279
            ],
            "sentiment_counts": {
                "POSITIVE": 9,
                "NEGATIVE": 1
            },
            "sentiment_distribution": {
                "POSITIVE": 0.9,
                "NEGATIVE": 0.1
            },
            "sentiment_overall": [
                "POSITIVE",
                0.9
            ]
        },
        "YC409": {
            "sentiment_labels": [
                "POSITIVE",
                "POSITIVE",
                "POSITIVE",
                "NEGATIVE",
                "POSITIVE",
                "POSITIVE",
                "NEGATIVE",
                "NEGATIVE",
                "NEGATIVE"
            ],
            "sentiment_scores": [
                0.9985820055007935,
                0.9243983626365662,
                0.9982233643531799,
                0.9970097541809082,
                0.9988318085670471,
                0.9984855055809021,
                0.9994895458221436,
                0.9982972741127014,
                0.9940181970596313
            ],
            "sentiment_counts": {
                "POSITIVE": 5,
                "NEGATIVE": 4
            },
            "sentiment_distribution": {
                "POSITIVE": 0.5555555555555556,
                "NEGATIVE": 0.4444444444444444
            },
            "sentiment_overall": [
                "POSITIVE",
                0.5555555555555556
            ]
        },
        "final_label": "POSITIVE",
        "final_count": 23,
        "final_proportion": 0.7931034482758621,
        "final_counts": {
            "POSITIVE": 23,
            "NEGATIVE": 6
        },
        "final_distribution": {
            "POSITIVE": 0.7931034482758621,
            "NEGATIVE": 0.20689655172413793
        }
    }
}