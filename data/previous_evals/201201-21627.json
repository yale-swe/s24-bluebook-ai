{
 "crn_code": "21627",
 "season": "201201",
 "legacy_coursetable_course_id": 15074,
 "enrollment": {
  "enrolled": 17,
  "responses": null,
  "declined": null,
  "no response": null
 },
 "ratings": [
  {
   "question_id": "YC005",
   "question_text": "Overall, how would you rate the workload of this course in comparison to other Yale courses you have taken?",
   "options": [
    "Much Less",
    "Less",
    "Same",
    "Greater",
    "Much Greater"
   ],
   "data": [
    0,
    1,
    5,
    5,
    1
   ]
  },
  {
   "question_id": "YC006",
   "question_text": "What is your overall assessment of this course?",
   "options": [
    "Poor",
    "Below Average",
    "Good",
    "Very Good",
    "Excellent"
   ],
   "data": [
    0,
    3,
    7,
    2,
    0
   ]
  },
  {
   "question_id": "YC007",
   "question_text": "Do you expect to use this class for credit toward your major, or toward a pre-professional program?",
   "options": [
    "Yes",
    "No"
   ],
   "data": [
    10,
    2
   ]
  }
 ],
 "narratives": [
  {
   "question_id": "YC004",
   "question_text": "How would you summarize ECON 110 05 for a fellow student? Would you recommend ECON 110 05 to another student? Why or why not?",
   "comments": [
    "Parallel programming cover some really interesting material - message passing, multithreading, and GPUs. The formal requirement is 223 but you might get more out of it having taken 323 and learned basic systems concepts. We spent a bit too much time timing code, but learning speedup techniques that you can implement on your own computer and the ability to use Yale's supercomputer for your problem sets is pretty cool.",
    "The course covers a lot of interesting things (MPI, openMP, p-threads, GPU, etc), but lecture is really boring. Every assignment except for one involves matrix multiplication using different things, and I would've enjoyed them a lot more if we actually did something different. Prof. Sherman is very knowledgeable but not very engaging - a few of my friends only went to 2-3 lectures all year, including the midterm. His slides are very descriptive though, and I learned a lot.",
    "Harder than I had originally thought, but pretty good. Thinking in parallel will challenge you in a good way. Mostly grad students in the class, but DON'T be afraid of that (undergrads did embarrassingly better on the midterm).",
    "We had five programming assignments spread over the course of the semester, with an average of 3 weeks to do each assignment. The assignments took me about 4 hours, 10 hours, 21 hours, 5 hours, and 12 hours, respectively, to do. Dr. Sherman extended the deadline for several of the assignments and gave you bonus points if you turned it in by theoriginal deadline. As far as the material, this class is basically about matrix multiplication and learning to use various APIs (MPI, OpenMP, PThreads, and CUDA). I think most of the conceptual and algorithmic stuff you will have already learned or know from previous classes. I felt like I didn't learn that much in class, and a lot of the programming assignments were VERY tedious, and a good chunk of the time (perhaps 25% or more) was spent just running lots and lots of tests, where I wasn't really learning anything. There's a required midterm and then you have the option to either take a final or do a final project. Dr. Sherman's PowerPoint presentations are VERY clear and the animations\/diagrams are VERY well done. He talks pretty slowly and goes pretty slowly, so it's fairly easy to follow. However, the material and his speaking style are a bit dry. I guess none of the material was that complicated and a lot of the APIs and device architectures I could have just looked up online, but realistically, I probably never would have learned or heard about any of these topics without taking this class.",
    "You'll learn about different methods of parallel computing and apply these methods to matrix multiplication or very similar problems. The homework assignments require you to spend a lot of time collecting data from your programs.",
    "I've come out of this class feeling like I've learned a few useful skills. We went over MPI (programming multiple processes that work together), OpenMP and pthreads for threading in C and last CUDA programming for nvidia gpus. That said, everything was matrix multiplication. I get that it's a good example of a problem that can be easily parallelized, but it got very repetitive.",
    "I think I would recommend 424, if you really liked 323 and\/or are interested in parallel techniques and memory hierarchy and optimization. We did learn really awesome things, especially how to program on GPUs and some suggestions for how to optimize programs based on the memory hierarchy. The class itself, though, moved a little slower than it needed to, and the 5 assignments took a good bit of time, in some cases longer than assignments in 323 took for me.",
    "Harder-than-expected course on various methods in parallel programming. You get to use the Yale HPCs and learn a lot about different ways to improve performance of canonical problems. You will learn how to do some cool things, but sometimes the problem sets weren't as interesting as they maybe could have been."
   ]
  }
 ],
 "extras": {
  "subject": "CPSC",
  "number": "424",
  "section": 1
 }
}