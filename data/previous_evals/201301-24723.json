{
 "crn_code": "24723",
 "season": "201301",
 "legacy_coursetable_course_id": 20860,
 "enrollment": {
  "enrolled": 7,
  "responses": null,
  "declined": null,
  "no response": null
 },
 "ratings": [
  {
   "question_id": "YC005",
   "question_text": "Overall, how would you rate the workload of this course in comparison to other Yale courses you have taken?",
   "options": [
    "Much Less",
    "Less",
    "Same",
    "Greater",
    "Much Greater"
   ],
   "data": [
    0,
    0,
    2,
    3,
    1
   ]
  },
  {
   "question_id": "YC006",
   "question_text": "What is your overall assessment of this course?",
   "options": [
    "Poor",
    "Below Average",
    "Good",
    "Very Good",
    "Excellent"
   ],
   "data": [
    0,
    1,
    3,
    2,
    0
   ]
  },
  {
   "question_id": "YC007",
   "question_text": "Do you expect to use this class for credit toward your major, or toward a pre-professional program?",
   "options": [
    "Yes",
    "No"
   ],
   "data": [
    6,
    0
   ]
  }
 ],
 "narratives": [
  {
   "question_id": "YC004",
   "question_text": "How would you summarize ECON 110 05 for a fellow student? Would you recommend ECON 110 05 to another student? Why or why not?",
   "comments": [
    "This class covers a lot of useful C language extensions, from MPI to OMP to pthreads to CUDA (GPU programming). These are obviously great skills to have, but I think we would benefit from spending more time on parallel programming theory. Cpsc 323, for example, spends very little time discussing how to complete the problem sets and much more covering systems theory. Some guidance in using the languages will be useful, but the Pacheco book covers MPI, Open MP, and pthreads very well. Spending more time on caches, memory optimizations, etc. and then studying such things in a more in-depth fashion on the problem sets would be good.The problem sets were fun, but I think the first MPI pset on matrix multiplication was tedious for the wrong reasons: triangular multiplication resulted in many small errors and edge cases. We could probably have implemented a simpler multiplication or just skipped that MPI pset altogether to give us time for a pthreads pset.The open MP pset was interesting, but parallelizing the serial algorithm for shortest path wasn't a very useful exercise, since the implementation we studied is almost fundamentally unparallelizable.Overall, this is a very straightforward class with 5-6 total psets that take no more than 15 hours. Most take less, especially if you've been paying attention in class. If you plan to do scientific computing, the skills you learn will be useful, but you could probably pick them up just as easily by reading the textbook yourself. The hard parts of parallel programming (caches, theory, memory, etc.) that would best be covered in a classroom are not really considered in this class (hopefully this might change in the future).I found the assignments enjoyable (hello world, matrix multiplication, N-body simulation, shortest path, and GPU multiplication), but the class material insufficiently stimulating. (Again, more complex theory would help this but also make the class more difficult).",
    "MPI, OpenMP, Pthreads, GPU\/Cuda. Pretty cool stuff would recommend. Problem sets aren't too bad.",
    "If you can maintain focus while context switching, take this class. The problem sets take a long time because you spend so much time waiting for your jobs to enter a queue. Even when it's just a couple seconds, it messes with your workflow. The problem sets are pretty difficult but all doable. Make sure to start them early.",
    "I will recommend it if you are interested in the material."
   ]
  }
 ],
 "extras": {
  "subject": "CPSC",
  "number": "424",
  "section": 1
 }
}